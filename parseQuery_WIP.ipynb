{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# parsequery work in progress\n",
    "import re\n",
    "\n",
    "\n",
    "query = '144'\n",
    "flight_pattern = re.compile(r'^(UAL|UA|GJS)(\\d+)$')\n",
    "# TODO: find a better way to handle this. Maybe regex. Need a system that classifies the query and assigns it a dedicated function like flight_deet or gate query.\n",
    "# Accounting for flight number query with leading alphabets\n",
    "match = flight_pattern.fullmatch(query)\n",
    "if match:\n",
    "    airline_code, flt_digits = match.groups()\n",
    "    print('\\nSearching for:', airline_code, flt_digits)\n",
    "    x = {'airlineCode': airline_code, 'fightNumber': flt_digits, 'type': 'flightNumber'}\n",
    "    print(x)\n",
    "else:\n",
    "    print('No match')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alphabetic airport ID 2618\n",
      "returning 3 item tuple, total id with/without/id_without_no_mets:\n",
      "17678/2618/1987\n",
      "alphabetic airport ID 2618\n",
      "returning 3 item tuple, total id with/without/id_without_no_mets:\n",
      "17678/2618/1987\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "Test done! no_weather_id/yes_weather_id:  0 / 6\n",
      "stored bulky_weather in self.bulky_weather\n",
      "Initiating the fetch now...\n",
      "total ID to pull:  1987\n",
      "done totals, saved in self.done 1955\n",
      "Nd totals saved in self.nd 32\n",
      "saved raw bulky weather return to self.weather\n",
      "Saved in self.bulky_metar\n",
      "exported as: C:\\Users\\ujasv\\OneDrive\\Desktop\\pickles\\bulk_metar202503161912.pkl\n",
      "Initiating the fetch now...\n",
      "TAF pull in progress...\n",
      "total ID to pull:  753\n",
      "done totals, saved in self.done 752\n",
      "Nd totals saved in self.nd 1\n",
      "saved raw bulky weather return to self.weather\n",
      "saved taf returns in self.bulky_taf\n",
      "exported as: C:\\Users\\ujasv\\OneDrive\\Desktop\\pickles\\bulk_taf202503161912.pkl\n",
      "Initiating DATIS extractor\n",
      "Total extracted: 76\n",
      "Saved: c:\\users\\ujasv\\onedrive\\desktop\\pickles\\datis_info_stack_202503161912.pkl\n",
      "Example at index 0: BOI ATIS INFO Z 1853Z. 11010KT 10SM OVC075 11/00 A2972 (TWO NINER SEVEN TWO). RNAV AND VISUAL APCHS IN USE. LNDG AND DEPG RWY 10L, 10R. NOTAMS... CLEARANCE DELIVERY PROVIDED BY GROUND CONTROL ON 121.7. ...ADVS YOU HAVE INFO Z.\n"
     ]
    }
   ],
   "source": [
    "# Safe to copy all this commented code and paste for bulk metar, taf and datis fetch and save\n",
    "\n",
    "from routes.root.WIPs.WIP_bulk_weather_extractor import Bulk_weather_extractor\n",
    "\n",
    "# For use in Jupyter\n",
    "we = Bulk_weather_extractor()\n",
    "x = we.airport_ID_separator()\n",
    "len(we.ids_without_digit_with_no_mets_excluded)\n",
    "\n",
    "# Do the test first to init necessary items\n",
    "metar_pull_test = we.scraper(test=True,)\n",
    "\n",
    "\n",
    "\n",
    "# shows syntax error but works on jupyter. Pulls bulk metar for last 15 days. Takes about 15-20 Seconds\n",
    "async_pull_metar = await we.parallel_scrape()\n",
    "\n",
    "# Automatically saves bulk_metar file name with current UTC YYYYMMDDHHMM \n",
    "we.hard_write_dumper(\"bulk_metar\",we.bulky_metar)\n",
    "\n",
    "# taf_pull_test = we.scraper(test=True,)\n",
    "\n",
    "# Pulls taf for last 17 days\n",
    "async_pull_taf = await we.parallel_scrape(taf_pull=True)\n",
    "\n",
    "# Automatically saves bulk_taf file name with current UTC YYYYMMDDHHMM \n",
    "we.hard_write_dumper(\"bulk_taf\",we.bulky_taf)\n",
    "\n",
    "# DATIS Extractor: Use in jupyter interactive. For use in terminal just change it to False \n",
    "a = await we.datis_extractor(jupyter=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match\n"
     ]
    }
   ],
   "source": [
    "query = '101'\n",
    "gate_pattern = re.compile(r'(\\d)|([0-9])')\n",
    "match = gate_pattern.fullmatch(query)\n",
    "if match:\n",
    "    terminal, num = match.groups()\n",
    "    print('\\nSearching for:', terminal, num)\n",
    "    x = {'terminal': terminal, 'gate': num, 'type': 'gate'}\n",
    "    print(x)\n",
    "else:\n",
    "    print('No match')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
