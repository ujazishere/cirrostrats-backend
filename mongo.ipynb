{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config.database import collection, collection_weather, collection_searchTrack, collection_flights, collection_gates, db_UJ\n",
    "from config.database_UJ import client\n",
    "from routes.root.root_class import Root_class, Fetching_Mechanism, Source_links_and_api, Root_source_links\n",
    "from bson import ObjectId\n",
    "import requests\n",
    "import datetime as dt\n",
    "import json\n",
    "import pickle\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "collection = collection_flights\n",
    "collection_backup = client['cirrostrats']['flights_backup']\n",
    "# collection = collection_searchTrack\n",
    "\n",
    "# get all documents. Expensive operation.\n",
    "# x = [i for i in collection.find({})]\n",
    "\n",
    "# return the first document\n",
    "# one = collection.find_one({})\n",
    "\n",
    "# Count documents\n",
    "# collection_backup.count_documents({})\n",
    "\n",
    "# Delete all documents from the collection\n",
    "# collection_backup.delete_many({})\n",
    "\n",
    "# Get backup flight numbers from collection_backup(inefficient since it scans all documents instead of just the flightNumber field) and insert them into the the empty collection_flights\n",
    "# !\n",
    "# docs = [{'flightNumber':i['flightNumber']} for i in collection_backup.find({})]\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# get only the flightNumber field from the collection_backup(efficient) documents instead of getting all the fields from document.\n",
    "# docs = [{'flightNumber':i['flightNumber']} \n",
    "        # for i in collection_backup.find({}, {'flightNumber': 1, '_id': 0})]\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "\n",
    "# This will insert flightnumbers in bulk in the collection if it doesnt exist - slow operation since it checks if the flightnumber already exist.\n",
    "\n",
    "update_operations = []\n",
    "docs = list(collection.find({}, {'_id': 0}))  # Exclude `_id` to prevent conflicts\n",
    "for i in docs:\n",
    "    flightNumber = i['flightID']\n",
    "    update_operations.append(\n",
    "        UpdateOne({'flightID': flightNumber},\n",
    "                  {'$set': {'flightID': flightNumber}},\n",
    "                  upsert=True\n",
    "                  )\n",
    "    ),\n",
    "result = collection_backup.bulk_write(update_operations)\n",
    "\n",
    "\n",
    "# match all documents. works like find. will fetch all that matches gjs in `flightNumber` fields\n",
    "# [i for i in collection_flights.find({'flightNumber':{'$regex': 'GJS'}})]\n",
    "\n",
    "\n",
    "\n",
    "# user_data = collection.find_one({\"email\": 'Anonymous'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': ObjectId('67e4559593bc5fc9ebd35ad8'),\n",
       "  'flightNumber': 'GJS4433',\n",
       "  'utc_updated_at': '2025-03-26T19:29:26.047837+00:00'}]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline = [\n",
    "    # {'$project': {'flightNumber': 1, '_id': 0}},\n",
    "    # {'$out': 'collection_flights'}\n",
    "# ]\n",
    "# collection_backup.aggregate(pipeline)\n",
    "\n",
    "\n",
    "\n",
    "import datetime as dt\n",
    "xx = dt.datetime.now(dt.UTC)\n",
    "# collection.delete_many({})\n",
    "collection.update_one(\n",
    "    {'flightNumber':'GJS4433'},\n",
    "     {\"$set\": \n",
    "      {'utc_updated_at': xx.isoformat()}},\n",
    "      upsert=True)\n",
    "[i for i in collection.find({})]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GJS4433']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b for _,b in collection.find_one({}, {'flightNumber': 1, '_id': 0}).items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xx = dt.datetime.now(dt.UTC)\n",
    "# q = [i for i in collection.find({'flightNumber':'SWA3422'})]\n",
    "# q = [i for i in collection.find({})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SD10', 'N1KA', 'DAL927', 'N418CT', 'N538CD']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# for a,b, in q[0].items():\n",
    "    # print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import redis\n",
    "r = redis.Redis(host=\"localhost\", port=6379, db=0, decode_responses=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "all_keys = [i for i in r.keys(\"*\")]\n",
    "all_keys.remove('multipleEntries')\n",
    "# db = [json.loads(r.get(i)) for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightDataVersioning:\n",
    "    \n",
    "    def retrieve_flight_versions(self, collection, flightID, options=None):\n",
    "        \"\"\"\n",
    "        Retrieve versions for a specific flight\n",
    "        \n",
    "        :param collection: MongoDB collection\n",
    "        :param flightID: Flight identifier\n",
    "        :param options: Optional filtering options\n",
    "            - start_date: Minimum version creation date\n",
    "            - end_date: Maximum version creation date\n",
    "            - limit: Maximum number of versions to retrieve\n",
    "        \"\"\"\n",
    "        # Base query\n",
    "        query = {'flightID': flightID}\n",
    "        \n",
    "        # Prepare projection to retrieve versions\n",
    "        projection = {\n",
    "            'versions': 1,\n",
    "            'latest_version_id': 1,\n",
    "            'last_updated': 1\n",
    "        }\n",
    "        \n",
    "        # Apply additional filtering if options provided\n",
    "        if options:\n",
    "            # Date range filtering for versions\n",
    "            if 'start_date' in options or 'end_date' in options:\n",
    "                version_filter = {}\n",
    "                if 'start_date' in options:\n",
    "                    version_filter['$gte'] = options['start_date']\n",
    "                if 'end_date' in options:\n",
    "                    version_filter['$lte'] = options['end_date']\n",
    "                \n",
    "                query['versions.version_created_at'] = version_filter\n",
    "            \n",
    "            # Limit number of versions\n",
    "            limit = options.get('limit', 0)\n",
    "        else:\n",
    "            limit = 0\n",
    "        \n",
    "        # Retrieve flight document\n",
    "        flight_doc = collection.find_one(query, projection)\n",
    "        \n",
    "        # Process versions if document exists\n",
    "        if flight_doc:\n",
    "            versions = flight_doc.get('versions', [])\n",
    "            \n",
    "            # Apply limit if specified\n",
    "            if limit > 0:\n",
    "                versions = versions[-limit:]\n",
    "            \n",
    "            return {\n",
    "                'versions': versions,\n",
    "                'latest_version_id': flight_doc.get('latest_version_id'),\n",
    "                'last_updated': flight_doc.get('last_updated')\n",
    "            }\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def create_version_indexes(self, collection):\n",
    "        \"\"\"\n",
    "        Create indexes for efficient version querying\n",
    "        \"\"\"\n",
    "        collection.create_index([\n",
    "            ('flightID', 1),\n",
    "            ('versions.version_created_at', -1)\n",
    "        ])\n",
    "        \n",
    "        collection.create_index([\n",
    "            ('flightID', 1),\n",
    "            ('latest_version_id', 1)\n",
    "        ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Mongo_migrate:\n",
    "\n",
    "    def time_conversion(self,ts:str):\n",
    "        # Method 1: fromisoformat() - Recommended for Python 3.11+\n",
    "        # parsed_dt = dt.datetime.fromisoformat(ts.replace('Z', '+00:00'))\n",
    "        \n",
    "        # Method 2: Using datetime.UTC (Python 3.11+)\n",
    "        return dt.datetime.fromisoformat(ts.replace('Z', '')).replace(tzinfo=dt.UTC)\n",
    "\n",
    "    def create_versioned_update_operations(self, r:redis.Redis, flightNumbers):\n",
    "        update_operations = []\n",
    "        \n",
    "        for flightID in flightNumbers:\n",
    "            # Get the individual item\n",
    "            key = flightID\n",
    "            flight_data: dict = r.get(key)\n",
    "            flight_data: dict = json.loads(flight_data)\n",
    "            \n",
    "            # Convert timestamp to datetime object\n",
    "            flight_data['timestamp'] = self.time_conversion(flight_data['timestamp'])\n",
    "            \n",
    "            # Generate a unique version ID\n",
    "            version_id = ObjectId()\n",
    "            \n",
    "            # Prepare the update operation with versioning\n",
    "            update_operations.append(\n",
    "                UpdateOne({'flightID': flightID},\n",
    "                        {'$push': {\n",
    "                            'versions': {\n",
    "                                '_id': version_id,\n",
    "                                **{k: v for k, v in flight_data.items() if k != 'versions'},\n",
    "                                'version_created_at': dt.datetime.now(dt.UTC)\n",
    "                            }\n",
    "                        }},\n",
    "                    upsert=True\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        return update_operations\n",
    "\n",
    "\n",
    "    def mongo_migrate(self, r:redis.Redis,):\n",
    "        flightNumbers:list = [key for key in r.keys(\"*\")]\n",
    "        flightNumbers.remove('multipleEntries')\n",
    "        update_operations = self.create_versioned_update_operations(r,flightNumbers)\n",
    "\n",
    "        # This is an outlaw. Makes no sense. clear it.\n",
    "        # collection.create_index(\n",
    "        #     [(\"utc_updated_at\", 1)],  # Index on `expiry_time` field\n",
    "        #     expireAfterSeconds=172800  # Documents expire 2 days (172800 seconds) after `expiry_time`\n",
    "        # )\n",
    "\n",
    "        collection.bulk_write(update_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = Mongo_migrate()\n",
    "mm.mongo_migrate(r)\n",
    "# collection.delete_many({})\n",
    "# collection.find_one({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup mongo migrate\n",
    "def mongo_migrate(r:redis.Redis,):\n",
    "    \n",
    "    flightNumbers:list = [key for key in r.keys(\"*\")]\n",
    "    flightNumbers.remove('multipleEntries')\n",
    "\n",
    "    update_operations = []\n",
    "\n",
    "    utc_now = dt.datetime.now(dt.UTC)\n",
    "\n",
    "    for flight_number in flightNumbers:\n",
    "        # Get the individual item\n",
    "        key = flight_number\n",
    "        flight_data:dict = r.get(key)\n",
    "        flight_data:dict = json.loads(flight_data)\n",
    "\n",
    "        flight_data['utc_updated_at'] = utc_now\n",
    "\n",
    "        update_operations.append(\n",
    "            UpdateOne({'flightNumber': flight_number},      # Finds the document with flightNumber.\n",
    "                    {'$set': flight_data},\n",
    "                    upsert=True,\n",
    "            )       \n",
    "        )\n",
    "    collection.create_index(\n",
    "        [(\"utc_updated_at\", 1)],  # Index on `expiry_time` field\n",
    "        expireAfterSeconds=172800  # Documents expire 2 days (172800 seconds) after `expiry_time`\n",
    "    )\n",
    "\n",
    "    collection.bulk_write(update_operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from schema.schemas import serialize_document_list\n",
    "query = \"\"    # Search for predertimined items in pipeline containing \"ap\"\n",
    "page = 1       # first page\n",
    "page_size = 50  # items per page\n",
    "suggestions = []\n",
    "# print('\\n\\n\\nTriggered /searches/suggestions', query, page, page_size)\n",
    "collection_merge = [collection, collection_flights] \n",
    "for coll in collection_merge:\n",
    "    pipeline = [\n",
    "            {\"$match\": {\"count\": {\"$exists\": True}}},        # filter documents that have a count field\n",
    "            {\"$match\": {\"$or\": [\n",
    "                {\"flightNumber\": {\"$regex\": query, \"$options\": \"i\"}},       # matches flightNumber field in flights collection\n",
    "                {\"name\": {\"$regex\": query, \"$options\": \"i\"}}                # matches name field in airport collection\n",
    "            ]}},\n",
    "            {\"$sort\": {\"count\": -1}},               # sort by popularity - the count field contains popularity rating.\n",
    "        ]\n",
    "    coll.aggregate(pipeline)\n",
    "    suggestions.extend(coll.aggregate(pipeline))\n",
    "\n",
    "\n",
    "# collection_merge[0].find_one({})\n",
    "# [i for i in serialize_document_list(suggestions)]  # serialize_document_list(suggestions]  # serialize_document_list(suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds `count` as 1 to all gjs flights \n",
    "with open(r'forMDB.pkl', 'rb') as f:\n",
    "    forMDB = pickle.load(f)\n",
    "GJS_scheduled_flights = forMDB['scheduled_flights']\n",
    "GJS_repo_flights = forMDB['repo_flights']\n",
    "popularity_raw = forMDB['popularity_raw']\n",
    "popularity_proportions = forMDB['popularity_proportions']\n",
    "\n",
    "# \n",
    "operations = []\n",
    "for i in GJS_scheduled_flights:\n",
    "# for airport, count in popularity_proportions.items():\n",
    "    flightNumber = \"GJS\"+str(i)\n",
    "    operation = UpdateOne(\n",
    "        {'flightNumber': flightNumber},\n",
    "        {'$set': {'count': 1}},\n",
    "        upsert=True\n",
    "    )\n",
    "    operations.append(operation)\n",
    "\n",
    "# Perform bulk write\n",
    "result = collection_flights.bulk_write(operations)\n",
    "# popularity_proportions\n",
    "# collection_flights.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = collection.find(query)\n",
    "\n",
    "\n",
    "suggestions = []\n",
    "\n",
    "query = \"g\"    # Search for predertimined items in pipeline containing \"ap\"\n",
    "page = 1        # \n",
    "page_size = 10\n",
    "\n",
    "collection_merge = [collection, collection_flights] \n",
    "for coll in collection_merge:\n",
    "    pipeline = [\n",
    "            {\"$match\": {\"count\": {\"$exists\": True}}},\n",
    "            {\"$match\": {\"$or\": [\n",
    "                {\"flightNumber\": {\"$regex\": query, \"$options\": \"i\"}},       # matches flightNumber field in flights collection\n",
    "                {\"name\": {\"$regex\": query, \"$options\": \"i\"}}                # matches name field in airport collection\n",
    "            ]}},\n",
    "            {\"$sort\": {\"count\": -1}},               # sort by popularity - the count field contains popularity rating.\n",
    "            # {\"$skip\": (page - 1) * page_size},    # the page number itself.\n",
    "            # {\"$limit\": page_size}                 # items per page\n",
    "        ]\n",
    "\n",
    "    suggestions.extend(coll.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_sug = int(len(suggestions)/20)\n",
    "\n",
    "x = [suggestions[i:i+20] for i in range(0,len(suggestions),20)]\n",
    "    \n",
    "    # new_sug.append(suggestions[i*10:(i+1)*10])\n",
    "    # break\n",
    "# slice suggestions into chunks of upto 10 per item in a list making a list of lists\n",
    "# list(range(0,len(suggestions),10))\n",
    "\n",
    "# len(x)\n",
    "# x[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'test_popular_suggestions.pkl', 'wb') as f:\n",
    "    # pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New UJ collection\n",
    "\n",
    "# from config.database_UJ import collection, collection_weather, collection_searchTrack\n",
    "from pymongo import UpdateOne\n",
    "from bson import ObjectId\n",
    "from config.database_UJ import client\n",
    "client.list_database_names()\n",
    "\n",
    "# db = client['cirrostrats']      # create a db\n",
    "# collection = db['']             # create a collection\n",
    "\n",
    "# all_db = db.list_collection_names()   # get all collections of the db\n",
    "# db = client.cirrostrats               # get a particular db\n",
    "# collection = db['flights']            # get a particular collection\n",
    "\n",
    "# collection.count_documents({})        # get the number of documents in the collection.\n",
    "\n",
    "# docs = [{'flightNumber':i} for i in flightNumbers]        # add flight numbers to the collection- fast operation\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# # This will insert flightnumbers in bulk in the collection if it doesnt exist - slow operation since it checks if the flightnumber already exist.\n",
    "# update_operations = []\n",
    "# for i in flightNumbers:\n",
    "#     update_operations.append(\n",
    "#         UpdateOne({'flightNumber': i},\n",
    "#                   {'$set': {'flightNumber': i}},\n",
    "#                   upsert=True\n",
    "#                   )\n",
    "#     )\n",
    "# result = collection_flights.bulk_write(update_operations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "xx = requests.get(\"http://3.15.228.76:8000/flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repo_flights = []\n",
    "scheduled_flights = []\n",
    "for i in xx.json()['flightNumbers']:\n",
    "    # first three digits are GJS, after those digits are flight number\n",
    "    # if len(i) == 7 and i[:3] == 'UAL' and i[3:].isnumeric():\n",
    "    if i[:3] == 'UAL' and i[3:].isnumeric():\n",
    "        # if i[3] == '4':\n",
    "        scheduled_flights.append(int(i[3:]))\n",
    "        # elif i[3] == '3':\n",
    "            # repo_flights.append(int(i[3:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scheduled_flights)\n",
    "# scheduled_flights_RPA = scheduled_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "jmsFlightNumbers = xx.json()['flightNumbers']\n",
    "# Saving these list of flight numbers into the collection flightNumbers\n",
    "\n",
    "# collection_flightNumbers.insert_many(jmsFlightNumbers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('JMS_flight_numbers.pkl', 'wb') as f:\n",
    "    pickle.dump(jmsFlightNumbers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from routes.root.weather_parse import Weather_parse\n",
    "from routes.root.dep_des import Pull_flight_info\n",
    "\n",
    "tots = {}\n",
    "flt_info = Pull_flight_info()\n",
    "for i in scheduled_flights:\n",
    "    rets = flt_info.fs_dep_arr_timezone_pull(i)\n",
    "    tots[rets['origin_fs']] = tots.get(rets['origin_fs'],0) + 1\n",
    "    tots[rets['destination_fs']] = tots.get(rets['destination_fs'],0) + 1\n",
    "    \n",
    "# Sorting the dictionary by values\n",
    "tots = {k: v for k, v in sorted(tots.items(), key=lambda item: item[1], reverse=True)}\n",
    "tots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tots = {}\n",
    "for a,b in tots.items():\n",
    "    sum_of_values = sum(tots.values())\n",
    "    new_tots[a] = int(b/sum_of_values*100)+1\n",
    "\n",
    "# list total number of values or keys in the dictionary\n",
    "tots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "forMDB = {'scheduled_flights': scheduled_flights, 'repo_flights': repo_flights, 'popularity_raw': tots, 'popularity_proportions': new_tots}\n",
    "\n",
    "with open(r'forMDB.pkl', 'wb') as f:\n",
    "    pickle.dump(forMDB, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config.database_UJ import collection, collection_weather, collection_searchTrack\n",
    "from config.database_UJ import client\n",
    "\n",
    "# list all db\n",
    "# client.list_database_names()\n",
    "\n",
    "# Make a new db\n",
    "# db = client.['db_name']\n",
    "\n",
    "# Make a new collection\n",
    "# collection = db['collection_name']\n",
    "\n",
    "# list all collections\n",
    "# all_db = db.list_collection_names()\n",
    "\n",
    "client['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "x = requests.get(\"http://3.15.228.76:8000/flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('testJmsFlights.json', 'w') as file:\n",
    "    # Write data to file\n",
    "    json.dump(x.json(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in x:\n",
    "\n",
    "    update_query = {\n",
    "        \"$setOnInsert\": {\"email\": data['email']},  # Only set email on document creation\n",
    "        \"$inc\": {f\"searches.{data['searchTerm']}\": 1},  # Increment count for this search term\n",
    "        \"$set\": {\"lastUpdated\": data['timestamp']}  # Update timestamp\n",
    "    }\n",
    "    # This single operation will:\n",
    "    # 1. Create document if email doesn't exist\n",
    "    # 2. Create searchTerm with count 1 if it doesn't exist\n",
    "    # 3. Increment count if searchTerm exists\n",
    "    result = collection_searchTrack.update_one(\n",
    "        {\"email\": data['email']},\n",
    "        update_query,\n",
    "        upsert=True\n",
    "    )\n",
    "\n",
    "    print({\"status\": \"success\", \"matched_count\": result.matched_count, \"modified_count\": result.modified_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searches\n",
    "y = [i for i in collection_searchTrack.find({})]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total flights 35205\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# extrac the data from the response - all flight numbers\n",
    "db = requests.get(\"http://3.15.228.76:8000/db\")\n",
    "\n",
    "response = db.json()\n",
    "result = response['db'] \n",
    "\n",
    "db = [i for i in result]\n",
    "print(\"total flights\", len(db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('flight_data.pkl', 'rb') as f:\n",
    "    xx = pickle.load(f)\n",
    "\n",
    "# with open('flight_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gjs_flight_numbers = [i for i in x if i[:3] == 'GJS']\n",
    "\n",
    "def gjs_returns(flightNumber):\n",
    "    return requests.get(f\"http://3.15.228.76:8000/flightData/{flightNumber}\")\n",
    "\n",
    "\n",
    "gjs_flight_data = [gjs_returns(i).json() for i in gjs_flight_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 38\n"
     ]
    }
   ],
   "source": [
    "registration = []\n",
    "for i in a:\n",
    "    registration.append(i['flightData']['registration'])\n",
    "\n",
    "print(len(registration),len(set(registration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N503GJ',\n",
       " 'N504GJ',\n",
       " 'N506GJ',\n",
       " 'N508GJ',\n",
       " 'N511GJ',\n",
       " 'N520GJ',\n",
       " 'N521GJ',\n",
       " 'N522GJ',\n",
       " 'N523GJ',\n",
       " 'N524GJ',\n",
       " 'N526GJ',\n",
       " 'N534GJ',\n",
       " 'N535GJ',\n",
       " 'N536GJ',\n",
       " 'N537GJ',\n",
       " 'N538GJ',\n",
       " 'N539GJ',\n",
       " 'N540GJ',\n",
       " 'N541GJ',\n",
       " 'N543GJ',\n",
       " 'N544GJ',\n",
       " 'N546GJ',\n",
       " 'N548GJ',\n",
       " 'N549GJ',\n",
       " 'N551GJ',\n",
       " 'N552GJ',\n",
       " 'N554GJ',\n",
       " 'N556GJ',\n",
       " 'N557GJ',\n",
       " 'N559GJ',\n",
       " 'N561GJ',\n",
       " 'N563GJ',\n",
       " 'N564GJ',\n",
       " 'N566GJ',\n",
       " 'N569GJ',\n",
       " 'N578GJ',\n",
       " 'N579GJ',\n",
       " None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(registration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
