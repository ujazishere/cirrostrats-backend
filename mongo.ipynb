{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config.database import client, collection_weather\n",
    "from config.database import collection_flights, client_UJ, db_UJ        # UJ mongoDB\n",
    "from core.root_class import Root_class, Fetching_Mechanism\n",
    "from bson import ObjectId\n",
    "import requests\n",
    "import datetime as dt\n",
    "import json\n",
    "import pickle\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "# db = client_UJ.cirrostrats                 # get a particular db\n",
    "cts = db_UJ['test_st']   # create/get a collection\n",
    "collection = collection_flights\n",
    "collection_st = collection_searchTrack\n",
    "# collection_backup = client_UJ['cirrostrats']['flights_backup']\n",
    "# collection = collection_searchTrack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_flights.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "search_index_collection = db_UJ['search_index']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index_collection.find_one({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect document hierarchy - type of field uniques\n",
    "    # Helpful to understand schema variations by field type across documents\n",
    "pipeline = [\n",
    "    {\"$project\": {\"fields\": {\"$objectToArray\": \"$$ROOT\"}}},\n",
    "    {\"$unwind\": \"$fields\"},\n",
    "    {\"$group\": {\"_id\": \"$fields.k\", \"types\": {\"$addToSet\": {\"$type\": \"$fields.v\"}}}},\n",
    "    {\"$project\": {\"field\": \"$_id\", \"_id\": 0, \"types\": 1}}\n",
    "]\n",
    "\n",
    "for doc in collection.aggregate(pipeline):\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect hierarchy of fields - usage and presence of fields across documents\n",
    "pipeline = [\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"arrayOfKeyValue\": {\"$objectToArray\": \"$$ROOT\"}\n",
    "            }\n",
    "        },\n",
    "        {\"$unwind\": \"$arrayOfKeyValue\"},\n",
    "        {\n",
    "            \"$group\": {\n",
    "                \"_id\": \"$arrayOfKeyValue.k\",\n",
    "                \"count\": {\"$sum\": 1},\n",
    "                \"percentage\": {\n",
    "                    \"$avg\": {\n",
    "                        \"$cond\": [{\"$ifNull\": [\"$arrayOfKeyValue.v\", False]}, 1, 0]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"field\": \"$_id\",\n",
    "                \"count\": 1,\n",
    "                \"percentage\": {\"$multiply\": [\"$percentage\", 100]},\n",
    "                \"_id\": 0\n",
    "            }\n",
    "        },\n",
    "        {\"$sort\": {\"count\": -1}}\n",
    "    ]\n",
    "    \n",
    "list(search_index_collection.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_flights.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect hierarchy - Find unique document Structures - Helpful when you have multiple variations of document in a collection\n",
    "collection = collection_flights\n",
    "\n",
    "\n",
    "def find_different_structures(collection, sample_size=5):\n",
    "    \"\"\"Find documents with different field structures\"\"\"\n",
    "    pipeline = [\n",
    "        {\n",
    "            \"$limit\": 1000\n",
    "        },\n",
    "        {\n",
    "            \"$group\": {\n",
    "                \"_id\": {\n",
    "                    \"fields\": {\n",
    "                        \"$map\": {\n",
    "                            \"input\": {\"$objectToArray\": \"$$ROOT\"},\n",
    "                            \"as\": \"field\",\n",
    "                            \"in\": \"$$field.k\"\n",
    "                        }\n",
    "                    }\n",
    "                },\n",
    "                \"count\": {\"$sum\": 1},\n",
    "                \"samples\": {\"$push\": {\"_id\": \"$_id\", \"doc\": \"$$ROOT\"}}\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"$project\": {\n",
    "                \"fields\": \"$_id.fields\",\n",
    "                \"count\": 1,\n",
    "                \"sample_docs\": {\"$slice\": [\"$samples\", sample_size]},\n",
    "                \"_id\": 0\n",
    "            }\n",
    "        },\n",
    "        {\"$sort\": {\"count\": -1}},\n",
    "        {\"$limit\": 10}\n",
    "    ]\n",
    "    \n",
    "    return list(collection.aggregate(pipeline, allowDiskUse=True))\n",
    "\n",
    "# Usage\n",
    "structures = find_different_structures(collection)\n",
    "for i, struct in enumerate(structures):\n",
    "    print(f\"\\nStructure {i+1}: {struct['count']} documents\")\n",
    "    print(f\"Fields: {sorted(struct['fields'])}\")\n",
    "    print(\"Sample _id:\", struct['sample_docs'][0]['_id'])\n",
    "\n",
    "# learn.mongodb.com      -- Validation of the schema\n",
    "# use validation to inspect schema for invalid documents - thru inverse validation \n",
    "# give me docs that dont adhere to my docs\n",
    "# After that sequential update many operations to fix those invalid docs\n",
    "#  Like if you find such docs x\n",
    "\n",
    "\n",
    "\n",
    "# Atlas search - b uild index\n",
    "\n",
    "# create text based search\n",
    "# single collection pattern\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_flights.count_documents({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_crit = {'ph':{\"$exists\":True}}       # return ones with popularity hits\n",
    "# self.return_crit = {'ph':0}       # return only flightID and ph\n",
    "c_sti_docs = list(cts.find(count_crit).sort('ph',-1))     # Reverse sort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "return_criteria = {'flightID':1,'versions':1}\n",
    "a = collection_flights.find({'flightID': {'$regex': 'N787MG'}}, return_criteria)  # find a document with flightID containing x.\n",
    "\n",
    "# collection_flights.count_documents({})  # count all documents in the collection\n",
    "# list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "pipeline = [\n",
    "    {\"$limit\": 10000},\n",
    "    # Unwind the versions array to examine each version individually\n",
    "    # {\"$unwind\": \"$versions\"},\n",
    "    \n",
    "    # Filter to keep only versions that have a clearance field\n",
    "    {\"$match\": \n",
    "        # {\"versions.clearance\": {\"$exists\": True}}},\n",
    "    \n",
    "    {'flightID': {'$regex': \"^UCA\"}}},\n",
    "    # Project the specific fields you need\n",
    "    {\"$project\": {'flightID':1, '_id':0}}\n",
    "        # \"c\": \"$versions\"  # Rename the versions object to clearance_data for clarity\n",
    "    # }},\n",
    "    \n",
    "    # Optional: If you only want one result per flight, you can group by flightID\n",
    "    # {\"$group\": {\n",
    "    #     \"_id\": \"$flightID\",\n",
    "    #     \"clearance_data\": {\"$first\": \"$clearance_data\"}\n",
    "    # }}\n",
    "]\n",
    "# Execute the pipeline on your collection\n",
    "# clearance_documents = list(collection_flights.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a test collection. Takes about a few 10 seconds. \n",
    "# collection_name = 'test_airports'\n",
    "# db = client.cirrostrats                 # get a particular db\n",
    "# collection_test = db[collection_name]   # create/get a collection\n",
    "# docs = [doc for doc in collection_airports_cache.find({}).limit(1000)]\n",
    "# collection_test.insert_many(docs)\n",
    "# cta = collection_test\n",
    "\n",
    "# # collection_es = collection_test\n",
    "# # id = [i['flightID'] for i in collection_es.find({},{'flightID':1, '_id':0})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mongo 101 - guide\n",
    "\n",
    "# list all db\n",
    "# client.list_database_names()\n",
    "# db = client['cirrostrats']            # create a db\n",
    "# collection = db['name_of_collection'] # create/get a collection. if it doesn't exist then get one.\n",
    "\n",
    "# db = client.cirrostrats               # get a particular db\n",
    "# all_db = db.list_collection_names()   # get all collections of the db\n",
    "# collection = db['flights']            # get a particular collection\n",
    "\n",
    "\n",
    "# ________________________________________________________\n",
    "\n",
    "# get all documents. Expensive operation.\n",
    "# x = [i for i in collection.find({})]\n",
    "\n",
    "# return the first document\n",
    "# one = collection.find_one({})\n",
    "\n",
    "# Count documents\n",
    "# collection_backup.count_documents({})\n",
    "\n",
    "# Delete all documents from the collection\n",
    "# collection_backup.delete_many({})\n",
    "\n",
    "# return the first document that have a `count` field using the $exists operator\n",
    "# collection.find_one({'count':{\"$exists\": True }})\n",
    "# collection.find({'submits': { '$exists': False } }))              # The other way around\n",
    "\n",
    "# returns just the flightID and excludes ObjectID fields. Very fast and efficient. first argument is the filter by and second is the projection. In this case, \n",
    "# filters all documents(first argument {}) and projection(second argument) returns just the flightID field and excludes the ObjectID.\n",
    "# criteria = {'flightID': 1, '_id': 0}\n",
    "# collection.find({}, criteria)\n",
    "\n",
    "# Get backup flight numbers from collection_backup(inefficient since it scans complete documents instead of just the flightNumber field) and insert them into the the empty collection\n",
    "# Avoid use since its inefficient.\n",
    "# docs = [{'flightNumber':i['flightNumber']} for i in collection_backup.find({})]\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# skim throguh only the flightID field from the collection(efficient) documents instead of getting all the fields from document.\n",
    "# docs = [{'flightID':doc['flightID']} \n",
    "        # for doc in collection_other.find({}, {'flightID': 1, '_id': 0})]\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# add flight numbers to the collection- fast operation. does not account for uniques and wont avoid duplicates.\n",
    "# docs = [{'flightNumber':i} for i in flightNumbers]\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# insert a key field and value in a document using set operator:\n",
    "# collection.update_one({'flightID':'GJS123'},{'$set':{'count':7.92193}})               # first arg is find_crit second arg is set_crit\n",
    "\n",
    "# rename a field within collection\n",
    "# collection.update_many(\n",
    "#     {'airport_st': {\"$exists\": True}},                        # find_crit\n",
    "#     {'$rename': {'airport_st': 'airportDisplayTerm'}}         # perform_crit\n",
    "# )\n",
    "\n",
    "# unset operator - remove a field from a document\n",
    "# collection.update_one({'flightID':'GJS123'},{'$unset':{'count':''}})\n",
    "\n",
    "\n",
    "# This will insert flightnumbers in bulk in the collection if it doesnt exist - slow operation since\n",
    "# it checks if the flightnumber already exist. !! WHY NOT SKIM THROUGH JUST flightID field instead of complete documents?\n",
    "# update_operations = []\n",
    "# docs = list(collection.find({}, {'_id': 0}))  # Exclude `_id` to prevent conflicts\n",
    "# for i in docs:\n",
    "#     flightNumber = i['flightID']\n",
    "#     update_operations.append(\n",
    "#         UpdateOne({'flightID': flightNumber},\n",
    "#                   {'$set': {'flightID': flightNumber}},\n",
    "#                   upsert=True\n",
    "#                   )\n",
    "#     ),\n",
    "# result = collection_backup.bulk_write(update_operations)\n",
    "\n",
    "# match all documents. works like find. will fetch all that matches gjs in `flightNumber` fields\n",
    "# [i for i in collection_flights.find({'flightNumber':{'$regex': 'GJS'}})]\n",
    "\n",
    "# match from the list provided.\n",
    "# list_of_items_to_be_matched = ['x','y','z',]  # for exmple this  could a list of flight numbers you want to match within the collection.\n",
    "# cfid = list(collection_flights.find({'flightID': {'$in': list(list_of_items_to_be_matched)}},{'flightID':1,} ))\n",
    "\n",
    "# limit documents to first 300. Saves memory and intensive operations.\n",
    "# a = collection.find().limit(300)\n",
    "\n",
    "# Copy entire collection to a new collection named 'test_new'\n",
    "# og_collection.aggregate([{'$out': 'test_new'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced mongo operations - pipepline and aggregation.\n",
    "\n",
    "# Typical use..\n",
    "# pipeline = [\n",
    "    # {\"$match\": {\"count\": {\"$exists\": True}}},        # filter documents that have a count field\n",
    "    # {'$project': {'flightNumber': 1, '_id': 0}},\n",
    "    # {'$out': 'collection_flights'}\n",
    "# ]\n",
    "\n",
    "\n",
    "# # collection_flights.find_one({})\n",
    "# # MongoDB aggregation pipeline to find all documents with a 'clearance' field in any nested dictionary within the 'versions' array\n",
    "# pipeline = [\n",
    "#     {\"$limit\": 10000},\n",
    "#     # Unwind the versions array to examine each version individually\n",
    "#     {\"$unwind\": \"$versions\"},\n",
    "    \n",
    "#     # Filter to keep only versions that have a clearance field\n",
    "#     {\"$match\": {\"versions.clearance\": {\"$exists\": True}}},\n",
    "    \n",
    "#     # Project the specific fields you need\n",
    "#     {\"$project\": {\n",
    "#         \"c\": \"$versions\"  # Rename the versions object to clearance_data for clarity\n",
    "#     }},\n",
    "    \n",
    "#     # Optional: If you only want one result per flight, you can group by flightID\n",
    "#     # {\"$group\": {\n",
    "#     #     \"_id\": \"$flightID\",\n",
    "#     #     \"clearance_data\": {\"$first\": \"$clearance_data\"}\n",
    "#     # }}\n",
    "# ]\n",
    "# # Execute the pipeline on your collection\n",
    "# clearance_documents = list(collection_flights.aggregate(pipeline))\n",
    "\n",
    "\n",
    "# filter match documents according to the query and sort. the $or operator matches either `flightNumber` or `name`(for airport collection)\n",
    "# collection_merge = [collection_airports, collection_flights] \n",
    "# for coll in collection_merge:\n",
    "#     pipeline = [\n",
    "#             {\"$match\": {\"count\": {\"$exists\": True}}},        # filter documents that have a count field\n",
    "#             {\"$match\": {\"$or\": [\n",
    "#                 {\"flightNumber\": {\"$regex\": query, \"$options\": \"i\"}},       # matches flightNumber field in flights collection\n",
    "#                 {\"name\": {\"$regex\": query, \"$options\": \"i\"}}                # matches name field in airport collection\n",
    "#             ]}},\n",
    "#             {\"$sort\": {\"count\": -1}},               # sort by popularity - the count field contains popularity rating.\n",
    "#         ]\n",
    "#     coll.aggregate(pipeline)\n",
    "#     suggestions.extend(coll.aggregate(pipeline))\n",
    "\n",
    "\n",
    "# Only return flightID from the root doc and version_created_at fields from the versions subdocument.\n",
    "#     '$project': {\n",
    "#         'flightID': 1,\n",
    "#         'version_timestamps': '$versions.version_created_at'\n",
    "\n",
    "# Change name field to uppercase in collection, e.g 'name': 'New York', will change to 'name': 'NEW YORK'\n",
    "    # '$project': {\n",
    "    #   'name': { '$toUpper': \"$name\" },\n",
    "\n",
    "# Group documents by field and sum their unique counts. e.g the 'route' field will be analysed for uniqueness and their counts.\n",
    "    # $group: {\n",
    "    #   _id: \"$route\",\n",
    "    #   count: { $sum: 1 }\n",
    "\n",
    "\n",
    "\n",
    "# collection.aggregate(pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returning all airports in the US with their ICAO and IATA codes -- checking consistency between the two codes. e.g KEWR and EWR vs KUNV and SCE\n",
    "icao = db_UJ['icao_iata']\n",
    "# icao.count_documents({'country_code': 'US'})\n",
    "find_criteria = {'country_code': 'US'}\n",
    "# us_airports = icao.find(find_criteria,{'icao': 1, 'iata': 1, 'airport':1,'_id': 0})\n",
    "us_airports = icao.find(find_criteria,{'icao': 1, 'iata': 1,'_id': 0})\n",
    "us_airports = list(us_airports)\n",
    "\n",
    "for i in us_airports:\n",
    "    two = list(i.values())\n",
    "    if type(two[1])!=float and str(two[1]) != 'nan':\n",
    "        if two[1][1:] == two[0]:\n",
    "            pass\n",
    "            # print(two[0], two[1])\n",
    "        else:\n",
    "            print(two[0], two[1])\n",
    "        # print(str(two[1])== 'nan')\n",
    "    # if two[1] != float('nan'):\n",
    "        # print(two[0], two[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis call\n",
    "import redis\n",
    "r = redis.Redis(host=\"localhost\", port=6379, db=0, decode_responses=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis call 2\n",
    "# import json\n",
    "\n",
    "# all_keys = [i for i in r.keys(\"*\")]\n",
    "# all_keys.remove('multipleEntries')\n",
    "\n",
    "# db = [json.loads(r.get(i)) for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: forMDB \n",
    "import requests\n",
    "xx = requests.get(\"http://3.15.228.76:8000/flights\")\n",
    "\n",
    "repo_flights = []\n",
    "scheduled_flights = []\n",
    "for i in xx.json()['flightNumbers']:\n",
    "    # first three digits are GJS, after those digits are flight number\n",
    "    # if len(i) == 7 and i[:3] == 'UAL' and i[3:].isnumeric():\n",
    "    if i[:3] == 'UAL' and i[3:].isnumeric():\n",
    "        # if i[3] == '4':\n",
    "        scheduled_flights.append(int(i[3:]))\n",
    "        # elif i[3] == '3':\n",
    "            # repo_flights.append(int(i[3:]))\n",
    "\n",
    "jmsFlightNumbers = xx.json()['flightNumbers']\n",
    "# Saving these list of flight numbers into the collection flightNumbers. !! WONT ACCOUNT FOR DUPLICATES!\n",
    "# collection_flightNumbers.insert_many(jmsFlightNumbers)\n",
    "\n",
    "import pickle\n",
    "with open('JMS_flight_numbers.pkl', 'wb') as f:\n",
    "    pickle.dump(jmsFlightNumbers, f)\n",
    "\n",
    "from routes.root.weather_parse import Weather_parse\n",
    "from routes.root.dep_des import Pull_flight_info\n",
    "\n",
    "tots = {}\n",
    "flt_info = Pull_flight_info()\n",
    "for i in scheduled_flights:\n",
    "    rets = flt_info.fs_dep_arr_timezone_pull(i)\n",
    "    tots[rets['origin_fs']] = tots.get(rets['origin_fs'],0) + 1\n",
    "    tots[rets['destination_fs']] = tots.get(rets['destination_fs'],0) + 1\n",
    "    \n",
    "# Sorting the dictionary by values\n",
    "tots = {k: v for k, v in sorted(tots.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "new_tots = {}\n",
    "for icao,flightIDs in tots.items():\n",
    "    sum_of_values = sum(tots.values())\n",
    "    new_tots[icao] = int(flightIDs/sum_of_values*100)+1\n",
    "\n",
    "forMDB = {'scheduled_flights': scheduled_flights, 'repo_flights': repo_flights, 'popularity_raw': tots, 'popularity_proportions': new_tots}\n",
    "\n",
    "with open(r'forMDB.pkl', 'wb') as f:\n",
    "    pickle.dump(forMDB, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 forMDB\n",
    "# adds `count` as 1 to all gjs flights \n",
    "with open(r'forMDB.pkl', 'rb') as f:\n",
    "    forMDB = pickle.load(f)\n",
    "GJS_scheduled_flights = forMDB['scheduled_flights']\n",
    "GJS_repo_flights = forMDB['repo_flights']\n",
    "popularity_raw = forMDB['popularity_raw']\n",
    "popularity_proportions = forMDB['popularity_proportions']\n",
    "\n",
    "# \n",
    "operations = []\n",
    "for i in GJS_scheduled_flights:\n",
    "# for airport, count in popularity_proportions.items():\n",
    "    flightNumber = \"GJS\"+str(i)\n",
    "    operation = UpdateOne(\n",
    "        {'flightNumber': flightNumber},\n",
    "        {'$set': {'count': 1}},\n",
    "        upsert=True\n",
    "    )\n",
    "    operations.append(operation)\n",
    "\n",
    "# Perform bulk write\n",
    "result = collection_flights.bulk_write(operations)\n",
    "# popularity_proportions\n",
    "# collection_flights.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gjs_reg = {'N503GJ',\n",
    " 'N504GJ',\n",
    " 'N506GJ',\n",
    " 'N508GJ',\n",
    " 'N511GJ',\n",
    " 'N520GJ',\n",
    " 'N521GJ',\n",
    " 'N522GJ',\n",
    " 'N523GJ',\n",
    " 'N524GJ',\n",
    " 'N526GJ',\n",
    " 'N534GJ',\n",
    " 'N535GJ',\n",
    " 'N536GJ',\n",
    " 'N537GJ',\n",
    " 'N538GJ',\n",
    " 'N539GJ',\n",
    " 'N540GJ',\n",
    " 'N541GJ',\n",
    " 'N543GJ',\n",
    " 'N544GJ',\n",
    " 'N546GJ',\n",
    " 'N548GJ',\n",
    " 'N549GJ',\n",
    " 'N551GJ',\n",
    " 'N552GJ',\n",
    " 'N554GJ',\n",
    " 'N556GJ',\n",
    " 'N557GJ',\n",
    " 'N559GJ',\n",
    " 'N561GJ',\n",
    " 'N563GJ',\n",
    " 'N564GJ',\n",
    " 'N566GJ',\n",
    " 'N569GJ',\n",
    " 'N578GJ',\n",
    " 'N579GJ',}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
