{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config.database import client, collection_airports, collection_weather, collection_searchTrack, collection_gates       #Luis mongoDB.\n",
    "from config.database import collection_flights, client_UJ, db_UJ        # UJ mongoDB\n",
    "from routes.root.root_class import Root_class, Fetching_Mechanism, Source_links_and_api, Root_source_links\n",
    "from bson import ObjectId\n",
    "import requests\n",
    "import datetime as dt\n",
    "import json\n",
    "import pickle\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "# db = client_UJ.cirrostrats                 # get a particular db\n",
    "cts = db_UJ['test_st']   # create/get a collection\n",
    "collection = collection_flights\n",
    "collection_st = collection_searchTrack\n",
    "# collection_backup = client_UJ['cirrostrats']['flights_backup']\n",
    "# collection = collection_searchTrack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "pipeline = [\n",
    "    {\"$limit\": 10000},\n",
    "    # Unwind the versions array to examine each version individually\n",
    "    # {\"$unwind\": \"$versions\"},\n",
    "    \n",
    "    # Filter to keep only versions that have a clearance field\n",
    "    {\"$match\": \n",
    "        # {\"versions.clearance\": {\"$exists\": True}}},\n",
    "    \n",
    "    {'flightID': {'$regex': \"^UCA\"}}},\n",
    "    # Project the specific fields you need\n",
    "    {\"$project\": {'flightID':1, '_id':0}}\n",
    "        # \"c\": \"$versions\"  # Rename the versions object to clearance_data for clarity\n",
    "    # }},\n",
    "    \n",
    "    # Optional: If you only want one result per flight, you can group by flightID\n",
    "    # {\"$group\": {\n",
    "    #     \"_id\": \"$flightID\",\n",
    "    #     \"clearance_data\": {\"$first\": \"$clearance_data\"}\n",
    "    # }}\n",
    "]\n",
    "# Execute the pipeline on your collection\n",
    "# clearance_documents = list(collection_flights.aggregate(pipeline))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a test collection. Takes about a few 10 seconds. \n",
    "# collection_name = 'test_airports'\n",
    "# db = client.cirrostrats                 # get a particular db\n",
    "# collection_test = db[collection_name]   # create/get a collection\n",
    "# docs = [doc for doc in collection_airports.find({}).limit(1000)]\n",
    "# collection_test.insert_many(docs)\n",
    "# cta = collection_test\n",
    "\n",
    "# # collection_es = collection_test\n",
    "# # id = [i['flightID'] for i in collection_es.find({},{'flightID':1, '_id':0})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mongo 101 - guide\n",
    "\n",
    "# list all db\n",
    "# client.list_database_names()\n",
    "# db = client['cirrostrats']            # create a db\n",
    "# collection = db['name_of_collection'] # create/get a collection. if it doesn't exist then get one.\n",
    "\n",
    "# db = client.cirrostrats               # get a particular db\n",
    "# all_db = db.list_collection_names()   # get all collections of the db\n",
    "# collection = db['flights']            # get a particular collection\n",
    "\n",
    "\n",
    "# ________________________________________________________\n",
    "\n",
    "# get all documents. Expensive operation.\n",
    "# x = [i for i in collection.find({})]\n",
    "\n",
    "# return the first document\n",
    "# one = collection.find_one({})\n",
    "\n",
    "# Count documents\n",
    "# collection_backup.count_documents({})\n",
    "\n",
    "# Delete all documents from the collection\n",
    "# collection_backup.delete_many({})\n",
    "\n",
    "# return the first document that have a `count` field using the $exists operator\n",
    "# collection.find_one({'count':{\"$exists\":True}})\n",
    "\n",
    "# returns just the flightID and excludes ObjectID fields. Very fast and efficient. first argument is the filter by and second is the projection. In this case, \n",
    "# filters all documents(first argument {}) and projection(second argument) returns just the flightID field and excludes the ObjectID.\n",
    "# criteria = {'flightID': 1, '_id': 0}\n",
    "# collection.find({}, criteria)\n",
    "\n",
    "# Get backup flight numbers from collection_backup(inefficient since it scans complete documents instead of just the flightNumber field) and insert them into the the empty collection\n",
    "# Avoid use since its inefficient.\n",
    "# docs = [{'flightNumber':i['flightNumber']} for i in collection_backup.find({})]\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# skim throguh only the flightID field from the collection(efficient) documents instead of getting all the fields from document.\n",
    "# docs = [{'flightID':doc['flightID']} \n",
    "        # for doc in collection_other.find({}, {'flightID': 1, '_id': 0})]\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# add flight numbers to the collection- fast operation. does not account for uniques and wont avoid duplicates.\n",
    "# docs = [{'flightNumber':i} for i in flightNumbers]\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# insert a key field and value in a document using set operator:\n",
    "# collection.update_one({'flightID':'GJS123'},{'$set':{'count':7.92193}})\n",
    "\n",
    "# unset operator - remove a field from a document\n",
    "# collection.update_one({'flightID':'GJS123'},{'$unset':{'count':''}})\n",
    "\n",
    "\n",
    "# This will insert flightnumbers in bulk in the collection if it doesnt exist - slow operation since\n",
    "# it checks if the flightnumber already exist. !! WHY NOT SKIM THROUGH JUST flightID field instead of complete documents?\n",
    "# update_operations = []\n",
    "# docs = list(collection.find({}, {'_id': 0}))  # Exclude `_id` to prevent conflicts\n",
    "# for i in docs:\n",
    "#     flightNumber = i['flightID']\n",
    "#     update_operations.append(\n",
    "#         UpdateOne({'flightID': flightNumber},\n",
    "#                   {'$set': {'flightID': flightNumber}},\n",
    "#                   upsert=True\n",
    "#                   )\n",
    "#     ),\n",
    "# result = collection_backup.bulk_write(update_operations)\n",
    "\n",
    "# match all documents. works like find. will fetch all that matches gjs in `flightNumber` fields\n",
    "# [i for i in collection_flights.find({'flightNumber':{'$regex': 'GJS'}})]\n",
    "\n",
    "# limit documents to first 300. Saves memory and intensive operations.\n",
    "# a = collection.find().limit(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced mongo operations - pipepline and aggregation.\n",
    "\n",
    "# Typical use..\n",
    "# pipeline = [\n",
    "    # {\"$match\": {\"count\": {\"$exists\": True}}},        # filter documents that have a count field\n",
    "    # {'$project': {'flightNumber': 1, '_id': 0}},\n",
    "    # {'$out': 'collection_flights'}\n",
    "# ]\n",
    "\n",
    "\n",
    "# # collection_flights.find_one({})\n",
    "# # MongoDB aggregation pipeline to find all documents with a 'clearance' field in any nested dictionary within the 'versions' array\n",
    "# pipeline = [\n",
    "#     {\"$limit\": 10000},\n",
    "#     # Unwind the versions array to examine each version individually\n",
    "#     {\"$unwind\": \"$versions\"},\n",
    "    \n",
    "#     # Filter to keep only versions that have a clearance field\n",
    "#     {\"$match\": {\"versions.clearance\": {\"$exists\": True}}},\n",
    "    \n",
    "#     # Project the specific fields you need\n",
    "#     {\"$project\": {\n",
    "#         \"c\": \"$versions\"  # Rename the versions object to clearance_data for clarity\n",
    "#     }},\n",
    "    \n",
    "#     # Optional: If you only want one result per flight, you can group by flightID\n",
    "#     # {\"$group\": {\n",
    "#     #     \"_id\": \"$flightID\",\n",
    "#     #     \"clearance_data\": {\"$first\": \"$clearance_data\"}\n",
    "#     # }}\n",
    "# ]\n",
    "# # Execute the pipeline on your collection\n",
    "# clearance_documents = list(collection_flights.aggregate(pipeline))\n",
    "\n",
    "\n",
    "# filter match documents according to the query and sort. the $or operator matches either `flightNumber` or `name`(for airport collection)\n",
    "# collection_merge = [collection_airports, collection_flights] \n",
    "# for coll in collection_merge:\n",
    "#     pipeline = [\n",
    "#             {\"$match\": {\"count\": {\"$exists\": True}}},        # filter documents that have a count field\n",
    "#             {\"$match\": {\"$or\": [\n",
    "#                 {\"flightNumber\": {\"$regex\": query, \"$options\": \"i\"}},       # matches flightNumber field in flights collection\n",
    "#                 {\"name\": {\"$regex\": query, \"$options\": \"i\"}}                # matches name field in airport collection\n",
    "#             ]}},\n",
    "#             {\"$sort\": {\"count\": -1}},               # sort by popularity - the count field contains popularity rating.\n",
    "#         ]\n",
    "#     coll.aggregate(pipeline)\n",
    "#     suggestions.extend(coll.aggregate(pipeline))\n",
    "\n",
    "\n",
    "# Only return flightID from the root doc and version_created_at fields from the versions subdocument.\n",
    "#     '$project': {\n",
    "#         'flightID': 1,\n",
    "#         'version_timestamps': '$versions.version_created_at'\n",
    "\n",
    "# Change name field to uppercase in collection, e.g 'name': 'New York', will change to 'name': 'NEW YORK'\n",
    "    # '$project': {\n",
    "    #   'name': { '$toUpper': \"$name\" },\n",
    "\n",
    "# Group documents by field and sum their unique counts. e.g the 'route' field will be analysed for uniqueness and their counts.\n",
    "    # $group: {\n",
    "    #   _id: \"$route\",\n",
    "    #   count: { $sum: 1 }\n",
    "\n",
    "\n",
    "\n",
    "# collection.aggregate(pipeline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis call\n",
    "import redis\n",
    "r = redis.Redis(host=\"localhost\", port=6379, db=0, decode_responses=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redis call 2\n",
    "# import json\n",
    "\n",
    "# all_keys = [i for i in r.keys(\"*\")]\n",
    "# all_keys.remove('multipleEntries')\n",
    "\n",
    "# db = [json.loads(r.get(i)) for i in a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: forMDB \n",
    "import requests\n",
    "xx = requests.get(\"http://3.15.228.76:8000/flights\")\n",
    "\n",
    "repo_flights = []\n",
    "scheduled_flights = []\n",
    "for i in xx.json()['flightNumbers']:\n",
    "    # first three digits are GJS, after those digits are flight number\n",
    "    # if len(i) == 7 and i[:3] == 'UAL' and i[3:].isnumeric():\n",
    "    if i[:3] == 'UAL' and i[3:].isnumeric():\n",
    "        # if i[3] == '4':\n",
    "        scheduled_flights.append(int(i[3:]))\n",
    "        # elif i[3] == '3':\n",
    "            # repo_flights.append(int(i[3:]))\n",
    "\n",
    "jmsFlightNumbers = xx.json()['flightNumbers']\n",
    "# Saving these list of flight numbers into the collection flightNumbers. !! WONT ACCOUNT FOR DUPLICATES!\n",
    "# collection_flightNumbers.insert_many(jmsFlightNumbers)\n",
    "\n",
    "import pickle\n",
    "with open('JMS_flight_numbers.pkl', 'wb') as f:\n",
    "    pickle.dump(jmsFlightNumbers, f)\n",
    "\n",
    "from routes.root.weather_parse import Weather_parse\n",
    "from routes.root.dep_des import Pull_flight_info\n",
    "\n",
    "tots = {}\n",
    "flt_info = Pull_flight_info()\n",
    "for i in scheduled_flights:\n",
    "    rets = flt_info.fs_dep_arr_timezone_pull(i)\n",
    "    tots[rets['origin_fs']] = tots.get(rets['origin_fs'],0) + 1\n",
    "    tots[rets['destination_fs']] = tots.get(rets['destination_fs'],0) + 1\n",
    "    \n",
    "# Sorting the dictionary by values\n",
    "tots = {k: v for k, v in sorted(tots.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "new_tots = {}\n",
    "for icao,flightIDs in tots.items():\n",
    "    sum_of_values = sum(tots.values())\n",
    "    new_tots[icao] = int(flightIDs/sum_of_values*100)+1\n",
    "\n",
    "forMDB = {'scheduled_flights': scheduled_flights, 'repo_flights': repo_flights, 'popularity_raw': tots, 'popularity_proportions': new_tots}\n",
    "\n",
    "with open(r'forMDB.pkl', 'wb') as f:\n",
    "    pickle.dump(forMDB, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 forMDB\n",
    "# adds `count` as 1 to all gjs flights \n",
    "with open(r'forMDB.pkl', 'rb') as f:\n",
    "    forMDB = pickle.load(f)\n",
    "GJS_scheduled_flights = forMDB['scheduled_flights']\n",
    "GJS_repo_flights = forMDB['repo_flights']\n",
    "popularity_raw = forMDB['popularity_raw']\n",
    "popularity_proportions = forMDB['popularity_proportions']\n",
    "\n",
    "# \n",
    "operations = []\n",
    "for i in GJS_scheduled_flights:\n",
    "# for airport, count in popularity_proportions.items():\n",
    "    flightNumber = \"GJS\"+str(i)\n",
    "    operation = UpdateOne(\n",
    "        {'flightNumber': flightNumber},\n",
    "        {'$set': {'count': 1}},\n",
    "        upsert=True\n",
    "    )\n",
    "    operations.append(operation)\n",
    "\n",
    "# Perform bulk write\n",
    "result = collection_flights.bulk_write(operations)\n",
    "# popularity_proportions\n",
    "# collection_flights.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "gjs_reg = {'N503GJ',\n",
    " 'N504GJ',\n",
    " 'N506GJ',\n",
    " 'N508GJ',\n",
    " 'N511GJ',\n",
    " 'N520GJ',\n",
    " 'N521GJ',\n",
    " 'N522GJ',\n",
    " 'N523GJ',\n",
    " 'N524GJ',\n",
    " 'N526GJ',\n",
    " 'N534GJ',\n",
    " 'N535GJ',\n",
    " 'N536GJ',\n",
    " 'N537GJ',\n",
    " 'N538GJ',\n",
    " 'N539GJ',\n",
    " 'N540GJ',\n",
    " 'N541GJ',\n",
    " 'N543GJ',\n",
    " 'N544GJ',\n",
    " 'N546GJ',\n",
    " 'N548GJ',\n",
    " 'N549GJ',\n",
    " 'N551GJ',\n",
    " 'N552GJ',\n",
    " 'N554GJ',\n",
    " 'N556GJ',\n",
    " 'N557GJ',\n",
    " 'N559GJ',\n",
    " 'N561GJ',\n",
    " 'N563GJ',\n",
    " 'N564GJ',\n",
    " 'N566GJ',\n",
    " 'N569GJ',\n",
    " 'N578GJ',\n",
    " 'N579GJ',}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
