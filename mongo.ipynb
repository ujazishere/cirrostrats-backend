{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from config.database import collection, collection_weather, collection_searchTrack, collection_flights, collection_gates\n",
    "from config.database_UJ import client\n",
    "from routes.root.root_class import Root_class, Fetching_Mechanism, Source_links_and_api, Root_source_links\n",
    "from bson import ObjectId\n",
    "import requests\n",
    "import datetime as dt\n",
    "import json\n",
    "import pickle\n",
    "from pymongo import UpdateOne\n",
    "\n",
    "# collection = collection_gates\n",
    "# collection = client['cirrostrats']['flights']\n",
    "# collection = collection_searchTrack\n",
    "# collection.estimated_document_count()\n",
    "\n",
    "# get all documents. Expensive operation.\n",
    "# x = [i for i in collection.find({})]\n",
    "\n",
    "# return the first document\n",
    "# one = collection.find_one({})\n",
    "# one\n",
    "\n",
    "# Delete all documents from the collection\n",
    "# x = collection.delete_many({})\n",
    "\n",
    "# match all documents. works like find. will fetch all that matches gjs in `flightNumber` fields\n",
    "# [i for i in collection_flights.find({'flightNumber':{'$regex': 'GJS'}})]\n",
    "\n",
    "\n",
    "\n",
    "# user_data = collection.find_one({\"email\": 'Anonymous'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schema.schemas import serialize_document_list\n",
    "query = \"g\"    # Search for predertimined items in pipeline containing \"ap\"\n",
    "page = 1       # first page\n",
    "page_size = 50  # items per page\n",
    "suggestions = []\n",
    "# print('\\n\\n\\nTriggered /searches/suggestions', query, page, page_size)\n",
    "collection_merge = [collection, collection_flights] \n",
    "for coll in collection_merge:\n",
    "    pipeline = [\n",
    "            {\"$match\": {\"count\": {\"$exists\": True}}},        # filter documents that have a count field\n",
    "            # {\"$project\": {\"_id\": 0, \"id\": {\"$toString\": \"$_id\"}, \"count\": 1}},  # Rename _id to id\n",
    "            # {\"$project\": {\"_id\": {\"$toString\": \"$_id\", \"count\": 1}}},\n",
    "            {\"$match\": {\"$or\": [\n",
    "                {\"flightNumber\": {\"$regex\": query, \"$options\": \"i\"}},       # matches flightNumber field in flights collection\n",
    "                {\"name\": {\"$regex\": query, \"$options\": \"i\"}}                # matches name field in airport collection\n",
    "            ]}},\n",
    "            {\"$sort\": {\"count\": -1}},               # sort by popularity - the count field contains popularity rating.\n",
    "            {\"$skip\": (page - 1) * page_size},    # the page number itself.\n",
    "            {\"$limit\": page_size}                 # items per page\n",
    "        ]\n",
    "    coll.aggregate(pipeline)\n",
    "    suggestions.extend(coll.aggregate(pipeline))\n",
    "# collection_merge[0].find_one({})\n",
    "# [i for i in serialize_document_list(suggestions)]  # serialize_document_list(suggestions]  # serialize_document_list(suggestions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds `count` as 1 to all gjs flights \n",
    "with open(r'forMDB.pkl', 'rb') as f:\n",
    "    forMDB = pickle.load(f)\n",
    "GJS_scheduled_flights = forMDB['scheduled_flights']\n",
    "GJS_repo_flights = forMDB['repo_flights']\n",
    "popularity_raw = forMDB['popularity_raw']\n",
    "popularity_proportions = forMDB['popularity_proportions']\n",
    "\n",
    "# \n",
    "operations = []\n",
    "for i in GJS_scheduled_flights:\n",
    "# for airport, count in popularity_proportions.items():\n",
    "    flightNumber = \"GJS\"+str(i)\n",
    "    operation = UpdateOne(\n",
    "        {'flightNumber': flightNumber},\n",
    "        {'$set': {'count': 1}},\n",
    "        upsert=True\n",
    "    )\n",
    "    operations.append(operation)\n",
    "\n",
    "# Perform bulk write\n",
    "result = collection_flights.bulk_write(operations)\n",
    "# popularity_proportions\n",
    "# collection_flights.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents = collection.find(query)\n",
    "\n",
    "\n",
    "suggestions = []\n",
    "\n",
    "query = \"g\"    # Search for predertimined items in pipeline containing \"ap\"\n",
    "page = 1        # \n",
    "page_size = 10\n",
    "\n",
    "collection_merge = [collection, collection_flights] \n",
    "for coll in collection_merge:\n",
    "    pipeline = [\n",
    "            {\"$match\": {\"count\": {\"$exists\": True}}},\n",
    "            {\"$match\": {\"$or\": [\n",
    "                {\"flightNumber\": {\"$regex\": query, \"$options\": \"i\"}},       # matches flightNumber field in flights collection\n",
    "                {\"name\": {\"$regex\": query, \"$options\": \"i\"}}                # matches name field in airport collection\n",
    "            ]}},\n",
    "            {\"$sort\": {\"count\": -1}},               # sort by popularity - the count field contains popularity rating.\n",
    "            # {\"$skip\": (page - 1) * page_size},    # the page number itself.\n",
    "            # {\"$limit\": page_size}                 # items per page\n",
    "        ]\n",
    "\n",
    "    suggestions.extend(coll.aggregate(pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_sug = int(len(suggestions)/20)\n",
    "\n",
    "x = [suggestions[i:i+20] for i in range(0,len(suggestions),20)]\n",
    "    \n",
    "    # new_sug.append(suggestions[i*10:(i+1)*10])\n",
    "    # break\n",
    "# slice suggestions into chunks of upto 10 per item in a list making a list of lists\n",
    "# list(range(0,len(suggestions),10))\n",
    "\n",
    "# len(x)\n",
    "# x[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r'test_popular_suggestions.pkl', 'wb') as f:\n",
    "    # pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New UJ collection\n",
    "\n",
    "# from config.database_UJ import collection, collection_weather, collection_searchTrack\n",
    "from pymongo import UpdateOne\n",
    "from bson import ObjectId\n",
    "from config.database_UJ import client\n",
    "client.list_database_names()\n",
    "\n",
    "db = client['cirrostrats']      # create a db\n",
    "collection = db['']        # create a collection\n",
    "\n",
    "# all_db = db.list_collection_names()   # get all collections of the db\n",
    "# db = client.cirrostrats               # get a particular db\n",
    "# collection = db['flights']               # get a particular collection\n",
    "\n",
    "# collection.estimated_document_count() # get the number of documents in the collection.\n",
    "\n",
    "# docs = [{'flightNumber':i} for i in flightNumbers]        # add flight numbers to the collection- fast operation\n",
    "# collection.insert_many(docs)\n",
    "\n",
    "# # This will insert flightnumbers in bulk in the collection if it doesnt exist - slow operation since it checks if the flightnumber already exist.\n",
    "# update_operations = []\n",
    "# for i in flightNumbers:\n",
    "#     update_operations.append(\n",
    "#         UpdateOne({'flightNumber': i},\n",
    "#                   {'$set': {'flightNumber': i}},\n",
    "#                   upsert=True\n",
    "#                   )\n",
    "#     )\n",
    "# result = collection_flights.bulk_write(update_operations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "xx = requests.get(\"http://3.15.228.76:8000/flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "repo_flights = []\n",
    "scheduled_flights = []\n",
    "for i in xx.json()['flightNumbers']:\n",
    "    # first three digits are GJS, after those digits are flight number\n",
    "    # if len(i) == 7 and i[:3] == 'UAL' and i[3:].isnumeric():\n",
    "    if i[:3] == 'UAL' and i[3:].isnumeric():\n",
    "        # if i[3] == '4':\n",
    "        scheduled_flights.append(int(i[3:]))\n",
    "        # elif i[3] == '3':\n",
    "            # repo_flights.append(int(i[3:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scheduled_flights)\n",
    "# scheduled_flights_RPA = scheduled_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "jmsFlightNumbers = xx.json()['flightNumbers']\n",
    "# Saving these list of flight numbers into the collection flightNumbers\n",
    "\n",
    "# collection_flightNumbers.insert_many(jmsFlightNumbers)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('JMS_flight_numbers.pkl', 'wb') as f:\n",
    "    pickle.dump(jmsFlightNumbers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from routes.root.weather_parse import Weather_parse\n",
    "from routes.root.dep_des import Pull_flight_info\n",
    "\n",
    "tots = {}\n",
    "flt_info = Pull_flight_info()\n",
    "for i in scheduled_flights:\n",
    "    rets = flt_info.fs_dep_arr_timezone_pull(i)\n",
    "    tots[rets['origin_fs']] = tots.get(rets['origin_fs'],0) + 1\n",
    "    tots[rets['destination_fs']] = tots.get(rets['destination_fs'],0) + 1\n",
    "    \n",
    "# Sorting the dictionary by values\n",
    "tots = {k: v for k, v in sorted(tots.items(), key=lambda item: item[1], reverse=True)}\n",
    "tots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tots = {}\n",
    "for a,b in tots.items():\n",
    "    sum_of_values = sum(tots.values())\n",
    "    new_tots[a] = int(b/sum_of_values*100)+1\n",
    "\n",
    "# list total number of values or keys in the dictionary\n",
    "tots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "forMDB = {'scheduled_flights': scheduled_flights, 'repo_flights': repo_flights, 'popularity_raw': tots, 'popularity_proportions': new_tots}\n",
    "\n",
    "with open(r'forMDB.pkl', 'wb') as f:\n",
    "    pickle.dump(forMDB, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config.database_UJ import collection, collection_weather, collection_searchTrack\n",
    "from config.database_UJ import client\n",
    "\n",
    "# list all db\n",
    "# client.list_database_names()\n",
    "\n",
    "# Make a new db\n",
    "# db = client.['db_name']\n",
    "\n",
    "# Make a new collection\n",
    "# collection = db['collection_name']\n",
    "\n",
    "# list all collections\n",
    "# all_db = db.list_collection_names()\n",
    "\n",
    "client['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "\n",
    "x = requests.get(\"http://3.15.228.76:8000/flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('testJmsFlights.json', 'w') as file:\n",
    "    # Write data to file\n",
    "    json.dump(x.json(), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in x:\n",
    "\n",
    "    update_query = {\n",
    "        \"$setOnInsert\": {\"email\": data['email']},  # Only set email on document creation\n",
    "        \"$inc\": {f\"searches.{data['searchTerm']}\": 1},  # Increment count for this search term\n",
    "        \"$set\": {\"lastUpdated\": data['timestamp']}  # Update timestamp\n",
    "    }\n",
    "    # This single operation will:\n",
    "    # 1. Create document if email doesn't exist\n",
    "    # 2. Create searchTerm with count 1 if it doesn't exist\n",
    "    # 3. Increment count if searchTerm exists\n",
    "    result = collection_searchTrack.update_one(\n",
    "        {\"email\": data['email']},\n",
    "        update_query,\n",
    "        upsert=True\n",
    "    )\n",
    "\n",
    "    print({\"status\": \"success\", \"matched_count\": result.matched_count, \"modified_count\": result.modified_count})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searches\n",
    "y = [i for i in collection_searchTrack.find({})]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total flights 35205\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# extrac the data from the response - all flight numbers\n",
    "db = requests.get(\"http://3.15.228.76:8000/db\")\n",
    "\n",
    "response = db.json()\n",
    "result = response['db'] \n",
    "\n",
    "db = [i for i in result]\n",
    "print(\"total flights\", len(db))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('flight_data.pkl', 'rb') as f:\n",
    "    xx = pickle.load(f)\n",
    "\n",
    "# with open('flight_data.pkl', 'wb') as f:\n",
    "#     pickle.dump(x, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gjs_flight_numbers = [i for i in x if i[:3] == 'GJS']\n",
    "\n",
    "def gjs_returns(flightNumber):\n",
    "    return requests.get(f\"http://3.15.228.76:8000/flightData/{flightNumber}\")\n",
    "\n",
    "\n",
    "gjs_flight_data = [gjs_returns(i).json() for i in gjs_flight_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169 38\n"
     ]
    }
   ],
   "source": [
    "registration = []\n",
    "for i in a:\n",
    "    registration.append(i['flightData']['registration'])\n",
    "\n",
    "print(len(registration),len(set(registration)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N503GJ',\n",
       " 'N504GJ',\n",
       " 'N506GJ',\n",
       " 'N508GJ',\n",
       " 'N511GJ',\n",
       " 'N520GJ',\n",
       " 'N521GJ',\n",
       " 'N522GJ',\n",
       " 'N523GJ',\n",
       " 'N524GJ',\n",
       " 'N526GJ',\n",
       " 'N534GJ',\n",
       " 'N535GJ',\n",
       " 'N536GJ',\n",
       " 'N537GJ',\n",
       " 'N538GJ',\n",
       " 'N539GJ',\n",
       " 'N540GJ',\n",
       " 'N541GJ',\n",
       " 'N543GJ',\n",
       " 'N544GJ',\n",
       " 'N546GJ',\n",
       " 'N548GJ',\n",
       " 'N549GJ',\n",
       " 'N551GJ',\n",
       " 'N552GJ',\n",
       " 'N554GJ',\n",
       " 'N556GJ',\n",
       " 'N557GJ',\n",
       " 'N559GJ',\n",
       " 'N561GJ',\n",
       " 'N563GJ',\n",
       " 'N564GJ',\n",
       " 'N566GJ',\n",
       " 'N569GJ',\n",
       " 'N578GJ',\n",
       " 'N579GJ',\n",
       " None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(registration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
